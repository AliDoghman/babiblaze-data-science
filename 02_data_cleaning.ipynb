{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6f3ccfd-2687-4d99-b7f0-52fc73e74d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 duplicate timestamps.\n",
      "Clean version saved: data_customer_noduplicates.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "df = pd.read_csv(\"data_customer.csv\")\n",
    "#data cleaning duplicate removal stage\n",
    "#TransactionID is 100% unique the rest are repeated\n",
    "#usually it will remove duplicates only if transactionID is repeated it will have no effect here\n",
    "#no need for duplicte search since it is unique as a dataset\n",
    "dupe_timestamps = df[df[\"Timestamp\"].duplicated(keep=False)].sort_values(\"Timestamp\")\n",
    "print(f\"Found {dupe_timestamps.shape[0]} duplicate timestamps.\")\n",
    "dupe_timestamps\n",
    "df.to_csv(\"data_customer_noduplicates.csv\", index=False)\n",
    "print(\"Clean version saved: data_customer_noduplicates.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3cee203-6df4-49f7-a5bd-f0f234e0886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removing duplicates: (101, 12)\n",
      "Removed 0 completely empty rows.\n",
      "CustomerID: 1 missing values\n",
      "Timestamp: 1 missing values\n",
      "Service: 1 missing values\n",
      "Remaining rows: (100, 12)\n",
      "Shape after removing placeholders: (100, 12)\n",
      " Final cleaned dataset saved as data_customer_cleaned.csv\n",
      "Remaining missing values:\n",
      "TransactionID         0\n",
      "Timestamp             0\n",
      "DayOfWeek             0\n",
      "BranchLocation        0\n",
      "CustomerID            0\n",
      "Gender                0\n",
      "Service               0\n",
      "Price (IDR)           0\n",
      "BarberName            0\n",
      "BarberTier            0\n",
      "Rating (1-5)          0\n",
      "Duration (Minutes)    0\n",
      "dtype: int64\n",
      "\n",
      "Final shape: (100, 12)\n"
     ]
    }
   ],
   "source": [
    "#no duplicates found we can go to next step in cleaning\n",
    "#ensuring every row have full valid info\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_customer_noduplicates.csv\")\n",
    "print(\"Dataset shape after removing duplicates:\", df.shape)\n",
    "df.head()\n",
    "#dropping empty rows\n",
    "before = df.shape[0]\n",
    "df.dropna(how=\"all\", inplace=True)\n",
    "after = df.shape[0]\n",
    "print(f\"Removed {before - after} completely empty rows.\")\n",
    "#check for missing values\n",
    "key_columns = [\"CustomerID\", \"Timestamp\", \"Service\"]\n",
    "for col in key_columns:\n",
    "    if col in df.columns:\n",
    "        missing = df[col].isna().sum()\n",
    "        print(f\"{col}: {missing} missing values\")\n",
    "# Display any rows missing critical info\n",
    "df[df[key_columns].isna().any(axis=1)]\n",
    "#Remove rows with missing info like customerid service or timestamp\n",
    "df = df.dropna(subset=[\"CustomerID\", \"Timestamp\", \"Service\"])\n",
    "print(\"Remaining rows:\", df.shape)\n",
    "#remove nonsense values rows \n",
    "mask = (\n",
    "    (df[\"CustomerID\"].astype(str).str.lower().isin([\"nan\", \"none\", \"null\", \"na\"])) |\n",
    "    (df[\"Service\"].astype(str).str.lower().isin([\"unknown\", \"na\", \"none\"]))\n",
    ")\n",
    "df = df[~mask]\n",
    "\n",
    "print(\"Shape after removing placeholders:\", df.shape)\n",
    "#save the new cleaned set\n",
    "df.to_csv(\"data_customer_cleaned.csv\", index=False)\n",
    "print(\" Final cleaned dataset saved as data_customer_cleaned.csv\")\n",
    "#final verification\n",
    "print(\"Remaining missing values:\")\n",
    "print(df.isna().sum())\n",
    "print(\"\\nFinal shape:\", df.shape)\n",
    "#our dataset now is fully cleaned \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62cc5363-c58d-4ef6-8a02-cd53ef5f0ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency converted: IDR → USD\n",
      "Service names translated to English (where possible).\n",
      "Saved standardized dataset as data_customer_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "#some data standarization into english since the dataset is indonsian transform price into usd and serives into english\n",
    "IDR_to_USD = 15500  # taken from internet sources\n",
    "# Create a new column for USD\n",
    "df[\"Price (USD)\"] = df[\"Price (IDR)\"] / IDR_to_USD\n",
    "# Round for readability\n",
    "df[\"Price (USD)\"] = df[\"Price (USD)\"].round(2)\n",
    "print(\"Currency converted: IDR → USD\")\n",
    "df[[\"Price (IDR)\", \"Price (USD)\"]].head(10)\n",
    "#service translation from indo to english \n",
    "service_translation = {\n",
    "    \"Cukur Rambut\": \"Haircut\",\n",
    "    \"Potong Jenggot\": \"Beard Trim\",\n",
    "    \"Cukur & Cuci\": \"Haircut + Wash\",\n",
    "    \"Cukur & Pijat\": \"Haircut + Massage\",\n",
    "    \"Cukur Anak\": \"Kids Haircut\",\n",
    "    \"Pewarnaan Rambut\": \"Hair Coloring\",\n",
    "    \"Perawatan Rambut\": \"Hair Treatment\"\n",
    "}\n",
    "# Apply translation only if values exist in dictionary\n",
    "df[\"Service (English)\"] = df[\"Service\"].map(service_translation).fillna(df[\"Service\"])\n",
    "print(\"Service names translated to English (where possible).\")\n",
    "df[[\"Service\", \"Service (English)\"]].drop_duplicates().head(10)\n",
    "#translate genders into english\n",
    "gender_map = {\n",
    "    \"Pria\": \"Male\",\n",
    "    \"Wanita\": \"Female\"\n",
    "}\n",
    "df[\"Gender (English)\"] = df[\"Gender\"].map(gender_map).fillna(df[\"Gender\"])\n",
    "df[\"Gender (English)\"].value_counts()\n",
    "#translate days of the week into english\n",
    "day_map = {\n",
    "    \"Senin\": \"Monday\",\n",
    "    \"Selasa\": \"Tuesday\",\n",
    "    \"Rabu\": \"Wednesday\",\n",
    "    \"Kamis\": \"Thursday\",\n",
    "    \"Jumat\": \"Friday\",\n",
    "    \"Sabtu\": \"Saturday\",\n",
    "    \"Minggu\": \"Sunday\"\n",
    "}\n",
    "df[\"DayOfWeek (English)\"] = df[\"DayOfWeek\"].map(day_map).fillna(df[\"DayOfWeek\"])\n",
    "df[\"DayOfWeek (English)\"].value_counts()\n",
    "\n",
    "#save updated version                                        \n",
    "df.to_csv(\"data_customer_standardized.csv\", index=False)\n",
    "print(\"Saved standardized dataset as data_customer_standardized.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cc53782-eacd-4613-baa0-52ce7358bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before final cleanup: (100, 16)\n",
      "Shape after dropping old columns: (100, 12)\n",
      "Remaining columns:\n",
      "['TransactionID', 'Timestamp', 'BranchLocation', 'CustomerID', 'BarberName', 'BarberTier', 'Rating (1-5)', 'Duration (Minutes)', 'Price (USD)', 'Service (English)', 'Gender (English)', 'DayOfWeek (English)']\n",
      "Remaining null values per column:\n",
      "TransactionID         0\n",
      "Timestamp             0\n",
      "BranchLocation        0\n",
      "CustomerID            0\n",
      "BarberName            0\n",
      "BarberTier            0\n",
      "Rating (1-5)          0\n",
      "Duration (Minutes)    0\n",
      "PriceUSD              0\n",
      "Service               0\n",
      "Gender                0\n",
      "DayOfWeek             0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n",
      "dataset saved as data_customer_final_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#final dataset version fully translated and dropping non english col\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_customer_standardized.csv\")\n",
    "print(\"Shape before final cleanup:\", df.shape)\n",
    "df.head(3)\n",
    "columns_to_drop = [\n",
    "    \"Price (IDR)\",\n",
    "    \"Service\",\n",
    "    \"Gender\",\n",
    "    \"DayOfWeek\"\n",
    "]\n",
    "\n",
    "# Drop only the ones that exist (safe drop)\n",
    "df.drop(columns=[c for c in columns_to_drop if c in df.columns], inplace=True)\n",
    "print(\"Shape after dropping old columns:\", df.shape)\n",
    "print(\"Remaining columns:\")\n",
    "print(df.columns.tolist())\n",
    "#rename for simplicity\n",
    "df.rename(columns={\n",
    "    \"Service (English)\": \"Service\",\n",
    "    \"Gender (English)\": \"Gender\",\n",
    "    \"DayOfWeek (English)\": \"DayOfWeek\",\n",
    "    \"Price (USD)\": \"PriceUSD\"\n",
    "}, inplace=True)\n",
    "df.head(5)\n",
    "#final small check \n",
    "print(\"Remaining null values per column:\")\n",
    "print(df.isna().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "#saving final version\n",
    "df.to_csv(\"data_customer_final_cleaned.csv\", index=False)\n",
    "print(\"dataset saved as data_customer_final_cleaned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
